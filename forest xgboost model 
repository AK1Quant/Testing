

```r
# Load necessary library
library(xgboost)

# Example training data (replace with your actual data)
train_data <- data.frame(
  VIX = runif(100)  # Replace with your actual VIX data
)

# Function to create features from time series data
create_features <- function(data, n_lags) {
  n <- nrow(data)
  X <- as.matrix(embed(data$VIX, n_lags + 1))
  colnames(X) <- paste0("Lag", n_lags:0)
  X <- X[, -1]  # Remove the last column which is the target variable
  y <- X[, "Lag0"]
  list(X = X, y = y)
}

# Define parameters for xgboost model
params <- list(
  objective = "reg:squarederror",
  max_depth = 3,
  eta = 0.1,
  nthread = 2
)

n_lags <- 5
new_data_length <- 200  # Length of the new data to forecast

# Prepare initial training data
features <- create_features(train_data, n_lags)
dtrain <- xgb.DMatrix(data = features$X, label = features$y)

# Train the initial xgboost model
model <- xgb.train(params, dtrain, nrounds = 100)

# Forecasting
all_data <- train_data$VIX
for (i in 1:(new_data_length - nrow(train_data))) {
  # Get the last n_lags observations
  last_obs <- tail(all_data, n_lags)
  
  # Predict the next 5 values
  pred <- predict(model, as.matrix(t(last_obs)))
  
  # Add the predicted values to the data
  all_data <- c(all_data, pred)
  
  # Update the training data and re-train the model with the newly available data
  if (length(all_data) > n_lags) {
    features <- create_features(data.frame(VIX = all_data), n_lags)
    dtrain <- xgb.DMatrix(data = features$X, label = features$y)
    model <- xgb.train(params, dtrain, nrounds = 100)
  }
}

# Plotting the forecasted values
plot(all_data, type = "l", col = "blue", main = "VIX Forecasting", xlab = "Time", ylab = "VIX")
abline(v = nrow(train_data), col = "red", lty = 2)  # Mark the end of original training data
```

### Explanation:
1. **Data Preparation**:
   - The `create_features` function creates lagged features for the time series data. It uses `embed` to create lagged variables.
   
2. **Model Training**:
   - An initial `xgboost` model is trained using the first set of lagged features.

3. **Iterative Forecasting**:
   - The loop iteratively predicts the next 5 values using the last 5 observations.
   - Predicted values are appended to the existing data.
   - The model is re-trained with the new data after adding the predicted values.

4. **Plotting**:
   - Finally, the full series including the forecasted values is plotted to visualize the forecast.

Adjust `train_data`, `params`, and other variables as per your specific requirements and dataset. This code demonstrates the general approach and should be tailored to fit your exact use case.