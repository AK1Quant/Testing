library(xgboost)
library(dplyr)

# Function to create lag features and moving averages
create_features <- function(data) {
  data <- as.numeric(data)
  df <- data.frame(
    lag1 = lag(data, 1),
    lag2 = lag(data, 2),
    lag3 = lag(data, 3),
    ma3 = zoo::rollmean(data, 3, fill = NA, align = "right"),
    ma5 = zoo::rollmean(data, 5, fill = NA, align = "right")
  )
  df <- df %>% drop_na()
  return(df)
}

# Function to predict future values and perform feature engineering
predict_and_engineer_features <- function(model, new_data, future_periods) {
  # Predict future values using the xgboost model
  dnew <- xgb.DMatrix(data = matrix(new_data, ncol = 1))
  predictions <- predict(model, dnew)
  
  # Create feature-engineered data frame from predictions
  features_df <- create_features(predictions)
  
  # Calculate the average of all features
  features_avg <- features_df %>% summarise(across(everything(), mean, na.rm = TRUE))
  
  return(features_avg)
}

# Example usage
set.seed(123) # For reproducibility
data <- rnorm(1887) # Replace this with your actual data

# Prepare the data for xgboost
dtrain <- xgb.DMatrix(data = matrix(data, ncol = 1), label = data)

# Train the xgboost model
params <- list(objective = "reg:squarederror", eval_metric = "rmse")
model <- xgboost(params = params, data = dtrain, nrounds = 100, verbose = 0)

# New data for prediction
new_data <- rnorm(100) # Replace this with your actual new data

# Predict and perform feature engineering
result <- predict_and_engineer_features(model, new_data, future_periods = 100)

# Print the result
print(result)